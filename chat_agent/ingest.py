from langchain.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain_community.embeddings import HuggingFaceBgeEmbeddings
from langchain.schema import Document
from config import *
import os
import re

def latex_block_splitter(text, chunk_size=500, chunk_overlap=50):
    # å…ˆæå–æ‰€æœ‰ \begin{}...\end{} block
    begin_end_pattern = re.compile(r'(\\begin\{.*?\}.*?\\end\{.*?\})', re.DOTALL)
    blocks = begin_end_pattern.split(text)

    chunks = []
    for block in blocks:
        if begin_end_pattern.match(block):
            # æ˜¯ \begin{}...\end{} å€å¡Šï¼Œç›´æ¥ä¿ç•™ç‚ºä¸€æ®µ
            chunks.append(block.strip())
        else:
            # è™•ç†å‰©ä¸‹çš„éƒ¨åˆ†
            command_pattern = re.compile(r'(\\[^\s]+)')
            parts = command_pattern.split(block)
            temp = ""
            for part in parts:
                if command_pattern.match(part):
                    # æ˜¯ \ é–‹é ­æŒ‡ä»¤ï¼Œç›´æ¥ç•¶ä¸€æ®µ
                    if temp:
                        chunks.append(temp.strip())
                        temp = ""
                    chunks.append(part.strip())
                else:
                    # æ™®é€šæ–‡å­—ï¼Œåˆ†æ®µçµ„è£
                    temp += part
                    if len(temp) >= chunk_size:
                        chunks.append(temp.strip())
                        temp = ""
            if temp:
                chunks.append(temp.strip())

    # æœ€å¾ŒåŠ ä¸Š overlap
    final_chunks = []
    for i in range(0, len(chunks), 1):
        combined = ""
        for j in range(max(0, i - chunk_overlap), min(len(chunks), i + 1)):
            combined += chunks[j] + "\n"
        final_chunks.append(combined.strip())

    print(f"âœ… å…±åˆ‡å‡º {len(final_chunks)} æ®µè½")
    return final_chunks


def ingest_pdfs():
    all_docs = []

    pdf_dir = "data/pdfs"
    for fname in os.listdir(pdf_dir):
        if fname.endswith(".pdf"):
            path = os.path.join(pdf_dir, fname)
            print(f"ğŸ“„ è¼‰å…¥ PDFï¼š{fname}")
            loader = PyPDFLoader(path)
            docs = loader.load()
            all_docs.extend(docs)

    #splitter = RecursiveCharacterTextSplitter(chunk_size=CHUNK_SIZE, chunk_overlap=CHUNK_OVERLAP)
    # æŠŠæ‰€æœ‰ document çš„å…§å®¹ä¸²èµ·ä¾†
    combined_text = "\n".join(doc.page_content for doc in all_docs)

    chunks = latex_block_splitter(combined_text, chunk_size=CHUNK_SIZE, chunk_overlap=CHUNK_OVERLAP)

    print(f"ğŸ“š ç¸½å…±åˆ‡å‡º {len(chunks)} æ®µè½")

    embedding = HuggingFaceBgeEmbeddings(
        model_name=EMBEDDING_MODEL,
        query_instruction=QUERY_INSTRUCTION
    )
    

    chunk_docs = [Document(page_content=chunk) for chunk in chunks]

    db = FAISS.from_documents(chunk_docs, embedding)
    db.save_local("vectorstore/faiss_index")
    print("âœ… å‘é‡ç´¢å¼•å·²å„²å­˜å®Œæˆ")

if __name__ == "__main__":
    ingest_pdfs()
